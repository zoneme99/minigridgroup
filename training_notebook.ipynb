{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c13378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "False\n",
      "None\n",
      "Observation Space: (84, 84, 3)\n",
      "Loading existing model from ctf_champion.zip...\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\Repo-Home\\07-Djup-Maskininlärning-MiniGrid-Agile-Bois\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\Repo-Home\\07-Djup-Maskininlärning-MiniGrid-Agile-Bois\\.venv\\Lib\\site-packages\\pettingzoo\\utils\\conversions.py:320: UserWarning: The `infos` dictionary returned by `env.reset` was empty. OverwritingAgent IDs will be used as keys\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 285   |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 114   |\n",
      "|    total_timesteps | 32768 |\n",
      "------------------------------\n",
      "Training Finished!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import supersuit as ss\n",
    "from stable_baselines3 import PPO\n",
    "from ctf_env import CaptureTheFlagPZ\n",
    "\n",
    "# --- Load Model ---\n",
    "# Set load_model to True if you want to continue training an existing model\n",
    "load_model = True \n",
    "model_path = \"ctf_champion.zip\"\n",
    "\n",
    "\n",
    "# --- Pick Device ---\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "\n",
    "\n",
    "# --- Grid Hyper Parameters ---\n",
    "grid_size = 21\n",
    "center_walls = 2 # The higher the number the fewer the walls  \n",
    "mirrored_walls = 15 # The lower the number the fewer walls\n",
    "# Example \n",
    "# First Training  (Easy) grid_size 12x12, center_walls 6, mirrored_walls 2 \n",
    "# Second Training (Medium) grid_size 16x16, center_walls 4, mirrored_walls 8 \n",
    "# Third Training  (Difficult/Default) grid_size 21x21, center_walls 2, mirrored_walls 15\n",
    "\n",
    "\n",
    "# --- Setup ---\n",
    "env = CaptureTheFlagPZ( \n",
    "    render_mode=\"rgb_array\", \n",
    "    grid_size=grid_size, \n",
    "    center_walls=center_walls, \n",
    "    mirrored_walls=mirrored_walls\n",
    "\n",
    ")\n",
    "\n",
    "env = ss.resize_v1(env, x_size=84, y_size=84)\n",
    "env = ss.color_reduction_v0(env, mode='full')\n",
    "env = ss.frame_stack_v1(env, 3)\n",
    "\n",
    "vec_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "vec_env = ss.concat_vec_envs_v1(vec_env, num_vec_envs=4, num_cpus=0, base_class='stable_baselines3')\n",
    "\n",
    "print(f\"Observation Space: {vec_env.observation_space.shape}\")\n",
    "# Should be (84, 84, 3) -> 84x84 pixels, 3 stacked frames\n",
    "\n",
    "\n",
    "# --- Load or Create Model ---\n",
    "if load_model == True and os.path.exists(model_path):\n",
    "    print(f\"Loading existing model from {model_path}...\")\n",
    "    model = PPO.load(model_path, env=vec_env, device=device)\n",
    "\n",
    "else:\n",
    "    print(f\"Training a new model...\")\n",
    "    model = PPO(\n",
    "        \"CnnPolicy\", \n",
    "        vec_env, \n",
    "        verbose=1, \n",
    "        batch_size=512, \n",
    "        learning_rate=1e-4, \n",
    "        ent_coef=0.01,\n",
    "        n_steps=2048,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Train Model ---\n",
    "print(\"Starting Training...\")\n",
    "model.learn(total_timesteps=30)\n",
    "print(\"Training Finished!\")\n",
    "\n",
    "model.save(\"ctf_champion\")\n",
    "# 3 million timesteps takes 444 min (8h) to train on a CPU  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb36330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cu128\n",
      "CUDA available: True\n",
      "CUDA version: 12.8\n",
      "GPU name: NVIDIA GeForce RTX 5070 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a43d63d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To train Gen 2 vs Gen 1, we need to convert the environment so 'Blue' is just a part of the game (like a moving wall).\n"
     ]
    }
   ],
   "source": [
    "import supersuit as ss\n",
    "from stable_baselines3 import PPO\n",
    "from ctf_env import CaptureTheFlagPZ\n",
    "\n",
    "#  Load the \"Old\" Champion (Gen 1)\n",
    "# We load it on CPU to avoid errors\n",
    "old_champion = PPO.load(\"ctf_champion\", device=\"cpu\")\n",
    "\n",
    "# 2. Define the Training Environment\n",
    "env = CaptureTheFlagPZ(render_mode=\"rgb_array\")\n",
    "env = ss.resize_v1(env, x_size=84, y_size=84)\n",
    "env = ss.color_reduction_v0(env, mode='full')\n",
    "env = ss.frame_stack_v1(env, 3)\n",
    "\n",
    "# 3. The \"Gauntlet\" Wrapper\n",
    "# We need a way to tell the environment: \"Blue actions come from the Old Model, Red actions come from the New Model\"\n",
    "# PettingZoo doesn't support this out of the box easily, so we usually just run a custom loop or\n",
    "# use a library like 'shimmy' to convert it to a Single-Agent Gym environment where the Opponent is part of the environment.\n",
    "\n",
    "print(\"To train Gen 2 vs Gen 1, we need to convert the environment so 'Blue' is just a part of the game (like a moving wall).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032c2d3",
   "metadata": {},
   "source": [
    "# Advanced Training\n",
    "Train the same model multiple times with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e4841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "False\n",
      "None\n",
      "Training a new model...\n",
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\Repo-Home\\07-Djup-Maskininlärning-MiniGrid-Agile-Bois\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Session 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\Repo-Home\\07-Djup-Maskininlärning-MiniGrid-Agile-Bois\\.venv\\Lib\\site-packages\\pettingzoo\\utils\\conversions.py:320: UserWarning: The `infos` dictionary returned by `env.reset` was empty. OverwritingAgent IDs will be used as keys\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 413   |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 79    |\n",
      "|    total_timesteps | 32768 |\n",
      "------------------------------\n",
      "Training Session 0 Finished!\n",
      "Loading existing model from models/bob/bob...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\Repo-Home\\07-Djup-Maskininlärning-MiniGrid-Agile-Bois\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:284: UserWarning: Path 'models\\bob' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n",
      "Starting Training Session 1...\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 214   |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 152   |\n",
      "|    total_timesteps | 32768 |\n",
      "------------------------------\n",
      "Training Session 1 Finished!\n",
      "Loading existing model from models/bob/bob...\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Starting Training Session 2...\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 242   |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 134   |\n",
      "|    total_timesteps | 32768 |\n",
      "------------------------------\n",
      "Training Session 2 Finished!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import supersuit as ss\n",
    "from stable_baselines3 import PPO\n",
    "from ctf_env import CaptureTheFlagPZ\n",
    "\n",
    "# --- Load Model ---\n",
    "# Set load_model to True if you want to continue training an existing model\n",
    "base_folder = \"models\"\n",
    "model_name = \"bob\"\n",
    "\n",
    "# --- Pick Device ---\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "\n",
    "\n",
    "# --- PPO Hyper Parameters ---\n",
    "# Training sets controls how many times you train the model\n",
    "training_sets=3\n",
    "learning_rate=[1e-4, 5e-5, 1e-5]\n",
    "ent_coef=[0.01, 0.01, 0.02]\n",
    "total_timesteps = [1_000_000, 1_000_000, 1_000_000]\n",
    "#total_timesteps = [30, 30, 30]\n",
    "\n",
    "# --- Grid Hyper Parameters ---\n",
    "grid_size = [12,16,21]\n",
    "center_walls = [6,4,2] # The higher the number the fewer the walls  \n",
    "mirrored_walls = [2,6,15] # The lower the number the fewer walls\n",
    "# Example \n",
    "# First Training  (Easy) grid_size 12x12, center_walls 6, mirrored_walls 2 \n",
    "# Second Training (Medium) grid_size 16x16, center_walls 4, mirrored_walls 8 \n",
    "# Third Training  (Difficult/Default) grid_size 21x21, center_walls 2, mirrored_walls 15\n",
    "\n",
    "\n",
    "for i in range(training_sets):\n",
    "    model_path = f\"{base_folder}/{model_name}/{model_name}\" \n",
    "    old_suffix = f\"_v{i}.zip\"\n",
    "    new_suffix = f\"_v{i+1}.zip\"\n",
    "\n",
    "    env = CaptureTheFlagPZ( \n",
    "        render_mode=\"rgb_array\", \n",
    "        grid_size=grid_size[i], \n",
    "        center_walls=center_walls[i], \n",
    "        mirrored_walls=mirrored_walls[i]\n",
    "    )\n",
    "\n",
    "    # --- Setup ---\n",
    "    env = ss.resize_v1(env, x_size=84, y_size=84)\n",
    "    env = ss.color_reduction_v0(env, mode='full')\n",
    "    env = ss.frame_stack_v1(env, 3)\n",
    "\n",
    "    vec_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "    vec_env = ss.concat_vec_envs_v1(vec_env, num_vec_envs=4, num_cpus=0, base_class='stable_baselines3')\n",
    "\n",
    "\n",
    "    # --- Create Model ---\n",
    "    if i == 0:\n",
    "\n",
    "        print(f\"Training a new model...\")\n",
    "        model = PPO(\n",
    "            \"CnnPolicy\", \n",
    "            vec_env, \n",
    "            verbose=1, \n",
    "            batch_size=512, \n",
    "            learning_rate=learning_rate[i], \n",
    "            ent_coef=ent_coef[i],\n",
    "            n_steps=2048,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(f\"Loading existing model from {model_path}...\")\n",
    "        model = PPO.load(\n",
    "            model_path+old_suffix, \n",
    "            env=vec_env, \n",
    "            device=device,\n",
    "            custom_objects={\n",
    "                \"learning_rate\": learning_rate[i],\n",
    "                \"ent_coef\": ent_coef[i]\n",
    "            }\n",
    "        )\n",
    " \n",
    "\n",
    "\n",
    "    # --- Train Model ---\n",
    "    print(f\"\\n\\nStarting Training Session {i+1}...\")\n",
    "    model.learn(total_timesteps=total_timesteps[i])\n",
    "    print(f\"Training Session {i+1} Finished!\")\n",
    "\n",
    "    model.save(model_path+new_suffix)\n",
    "    # 3 million timesteps takes 444 min (8h) to train on a CPU  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
