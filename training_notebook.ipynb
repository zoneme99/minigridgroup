{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c13378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "True\n",
      "12.8\n",
      "Observation Space: (84, 84, 3)\n",
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Starting Training...\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 1528  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 21    |\n",
      "|    total_timesteps | 32768 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1333         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076325606 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.948       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00299     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    value_loss           | 0.0202       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1295         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081705665 |\n",
      "|    clip_fraction        | 0.0708       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | -0.0378      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.000295     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    value_loss           | 0.0331       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1266        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008770052 |\n",
      "|    clip_fraction        | 0.0898      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.0154     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00761    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    value_loss           | 0.0866      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1249        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007973779 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.0641     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0108      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00779    |\n",
      "|    value_loss           | 0.0292      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1239        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009576712 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.0184     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00535    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00877    |\n",
      "|    value_loss           | 0.0999      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1228       |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 186        |\n",
      "|    total_timesteps      | 229376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00967071 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | -0.0233    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0136     |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00931   |\n",
      "|    value_loss           | 0.0965     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1224        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010448435 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | -0.00967    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.044       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    value_loss           | 0.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1219        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 241         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011022289 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.984      |\n",
      "|    explained_variance   | -0.342      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0109     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0316      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1215         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 269          |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0119890245 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.951       |\n",
      "|    explained_variance   | 0.00221      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.122        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    value_loss           | 0.439        |\n",
      "------------------------------------------\n",
      "Training Finished!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import supersuit as ss\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from ctf_env import CaptureTheFlagPZ\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "\n",
    "# Initialize PettingZoo Env\n",
    "env = CaptureTheFlagPZ(render_mode=\"rgb_array\")\n",
    "\n",
    "\n",
    "env = ss.resize_v1(env, x_size=84, y_size=84)\n",
    "env = ss.color_reduction_v0(env, mode='full')\n",
    "env = ss.frame_stack_v1(env, 3)\n",
    "\n",
    "# Convert to SB3 Vector Env\n",
    "# This allows PPO to see \"Red\" and \"Blue\" as just two independent samples in a batch\n",
    "vec_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "# Concatenate them so PPO trains on 2 agents at once\n",
    "# num_vec_envs=4 to better utilize GPU\n",
    "vec_env = ss.concat_vec_envs_v1(vec_env, num_vec_envs=4, num_cpus=0, base_class='stable_baselines3')\n",
    "\n",
    "print(f\"Observation Space: {vec_env.observation_space.shape}\")\n",
    "# Should be (84, 84, 3) -> 84x84 pixels, 3 stacked frames\n",
    "\n",
    "# Train with PPO\n",
    "# We use CnnPolicy because we are using images\n",
    "# Added device=\"cpu\" to bypass the GPU error\n",
    "# Increased batch size to fully utilize GPU memory\n",
    "model = PPO(\"CnnPolicy\", vec_env, verbose=1, batch_size=512, learning_rate=1e-4, device=device)\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "model.learn(total_timesteps=300000)\n",
    "print(\"Training Finished!\")\n",
    "\n",
    "# 5. Save the Champion\n",
    "model.save(\"ctf_champion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb36330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cu128\n",
      "CUDA available: True\n",
      "CUDA version: 12.8\n",
      "GPU name: NVIDIA GeForce RTX 5070 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a43d63d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To train Gen 2 vs Gen 1, we need to convert the environment so 'Blue' is just a part of the game (like a moving wall).\n"
     ]
    }
   ],
   "source": [
    "import supersuit as ss\n",
    "from stable_baselines3 import PPO\n",
    "from ctf_env import CaptureTheFlagPZ\n",
    "\n",
    "#  Load the \"Old\" Champion (Gen 1)\n",
    "# We load it on CPU to avoid errors\n",
    "old_champion = PPO.load(\"ctf_champion\", device=\"cpu\")\n",
    "\n",
    "# 2. Define the Training Environment\n",
    "env = CaptureTheFlagPZ(render_mode=\"rgb_array\")\n",
    "env = ss.resize_v1(env, x_size=84, y_size=84)\n",
    "env = ss.color_reduction_v0(env, mode='full')\n",
    "env = ss.frame_stack_v1(env, 3)\n",
    "\n",
    "# 3. The \"Gauntlet\" Wrapper\n",
    "# We need a way to tell the environment: \"Blue actions come from the Old Model, Red actions come from the New Model\"\n",
    "# PettingZoo doesn't support this out of the box easily, so we usually just run a custom loop or\n",
    "# use a library like 'shimmy' to convert it to a Single-Agent Gym environment where the Opponent is part of the environment.\n",
    "\n",
    "print(\"To train Gen 2 vs Gen 1, we need to convert the environment so 'Blue' is just a part of the game (like a moving wall).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.5 (venvp312)",
   "language": "python",
   "name": "venvp312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
